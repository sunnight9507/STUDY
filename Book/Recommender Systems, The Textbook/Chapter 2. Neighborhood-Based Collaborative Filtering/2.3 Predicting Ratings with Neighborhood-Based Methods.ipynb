{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **이웃 기반 방법**의 기본 아이디어는 **사용자 항목 유사성을 사용하여 등급 매트릭스에서 추천하는 것**이다.\n",
    "- 이웃의 개념은 예측을 하기 위해 유사한 사용자 또는 유사한 항목을 결정하는 것을 의미한다.\n",
    "- 다음에서 특정 사용자 항목 조합의 등급을 예측하는 데 이웃 기반 방법을 사용하는 방법에 대해 설명한다.\n",
    "- 이웃 기반 방벙에는 두 가지 기본 원칙이 있다.\n",
    "\n",
    "> ### User-based models\n",
    "- **비슷한 사용자들은 같은 항목에서 비슷한 등급을 가지고 있다.**\n",
    "- 만약 Alice와 Bob이 과거에 비슷한 방식으로 영화를 평가했다면 영화 터미네이터에서 Alice의 관찰된 등급을 사용하여 이 영화에 대한 Bob의 관찰되지 않은 등급을 예측할 수 있다.\n",
    "\n",
    "> ### Item-based models\n",
    "- **비슷한 항목은 같은 사용자에 의해 비슷한 방식으로 평가된다.**\n",
    "- Alien 및 Predator와 같은 유사한 공상 과학 영화에 대한 Bob의 평가를 사용하여 Terminator에 대한 평가를 예측할 수 있다.\n",
    "\n",
    "> - 협업 필터링 문제는 분류/회귀 모델링 문제의 일반화로 볼 수 있기 때문에, 이웃 기반 방법은 기계 학습에서 가장 가까운 이웃 분류기의 일반화로 볼 수 있다.\n",
    "- 가장 가까운 이웃이 항상 행 유사도에 기초하여 결정되는 분류와는 달리, 협업 필터링은 행 또는 열을 기반으로 이웃을 찾을 수 있다.\n",
    "- 이는 분류에서 모든 누락된 항목이 하나의 열에 집중되는 반면, 협업 필터링에서는 누락된 항목이 서로 다른 행과 열에 분산되어 있다.\n",
    "\n",
    "# 2.3.1 User-Based Neighborhood Models\n",
    "\n",
    "> - 이 접근 방식에서는 평가 예측이 계산되는 **대상 사용자와 유사한 사용자를 식별하기 위해 사용자 기반 이웃이 정의**된다.\n",
    "- **사용자 $i$의 이웃을 결정하기 위해 다른 모든 사용자와의 유사성을 계산**한다.\n",
    "- 따라서 **사용자가 지정한 등급간 유사성 함수를 정의**해야 한다.\n",
    "- 이러한 유사성 계산은 사용자마다 다른 등급 척도를 가질 수 있기 때문에 까다롭다.\n",
    "    - 한 사용자는 대부분의 항목을 좋아하는 쪽으로 치우칠 수 있는 반면, 다른 사용자는 대부분의 항목을 싫어하는 쪽으로 치우칠 수 있다.\n",
    "    - 또한 사용자마다 다른 항목에 등급을 매겼을 수 있다.\n",
    "- 따라서 이러한 문제를 해결하기 위한 방법이 필요하다.\n",
    "\n",
    "> - $m$ 사용자 및 $n$ 개의 항목이 있는 $m$ X $n$ 등급 매트릭스 $R = [r_{ui}]$의 경우, $I_u$는 사용자(행) $u$가 등급을 지정한 항목 인덱스 집합을 나타낸다. 예를 들어, 사용자 (행) $u$의 첫 번째, 세 번째 및 다섯 번째 항목의 등급이 지정(관찰)되고 나머지 항목이 누락된 경우 $I_u = \\{1, 3, 5\\}$이다. 따라서 사용자 $u$와 $v$가 모두 평가 한 항목 집합은 $I_u \\cap I_v$로 지정된다.\n",
    "- 예를 들어 사용자 $v$가 처음 $4$개 항목을 평가 한 경우 $I_v = \\{1, 2, 3, 4\\}$로 볼 수 있고 $I_u \\cap I_v = \\{1, 3, 5\\} \\cap \\{1, 2, 3, 4\\} = \\{1, 3\\}$로 볼 수 있다.\n",
    "- 집합 $I_u \\cap I_v$ 는 이웃 계산을 위해 $u$번째 사용자와 $v$번째 사용자 간의 유사성을 계산하는 데 사용되는 상호 관찰된 등급을 의미한다.\n",
    "\n",
    "> - 두 사용자 $u$와 $v$의 등급 벡터 사이의 유사도 $Sim(u, v)$를 계산하는 한 가지 척도는 $Pearson$ 상관 계수다.\n",
    "- **첫 번째 단계**는 지정된 등급을 사용하여 **각 사용자 $u$에 대한 평균을 계산**하는 것이다.\n",
    "- $$\\mu_u = \\frac{\\sum _{k \\in I_u} r_{uk}}{|Iu|} \\quad  \\forall u \\in \\{1...m\\} \\qquad (2.1) $$\n",
    "- 다음으로 사용자 $u$와 $v$ 사이의 $Pearson$ 상관 계수는 다음과 같이 정의된다.\n",
    "- $$ Sim(u, v) = Pearson(u, v) = \\frac{\\sum _{k \\in I_u \\cap I_v} (r_{uk} - \\mu_u) \\cdot (r_{vk} - \\mu_v)}{ \\sqrt{\\sum _{k \\in I_u \\cap I_v} (r_{uk} - \\mu_u)^2 } \\cdot \\sqrt{\\sum _{k \\in I_u \\cap I_v} (r_{vk} - \\mu_v)^2 }} \\qquad (2.2)$$\n",
    "- 엄밀히 말하면 **$Pearson (u, v)$의 전통적인 정의는 사용자 $u$와 $v$가 모두 평가한 항목에 대해서만 $\\mu_u$ 및 $\\mu_v$ 값을 계산**해야 한다고 규정한다.\n",
    "    - 식 $(2.1)$과 달리 이러한 접근 방식은 다른 사용자 $v$가 평가한 항목에 따라 $\\mu_u$값이 달라진다.\n",
    "- 그러나 식 $(2.1)$에 따라 각 $\\mu_u$를 각 사용자 $u$에 대해 **단 한 번만 계산하는 것이 상당히 일반적**이다(그리고 **계산적으로 더 간단**하다).\n",
    "- $\\mu_u$를 계산하는이 두 가지 방법 중 하나가 항상 다른 방법보다 더 나은 추천을 한다고 주장하기는 어렵다.\n",
    "- 극단적인 경우, 두 사용자가 상호 지정된 등급이 하나만 있는 경우, $\\mu_u$ 계산에 식 $(2.1)$을 사용하면 더 유용한 결과를 얻을 수 있다고 주장한다.\n",
    "- 따라서 이 장에서는 간단한 식 $(2.1)$을 사용할 것이다.\n",
    "- 한편, 대부분 사용자 기반 방법을 구현할 때 $Pearson$ 계산 중에 두 사용자가 모두 평가한 항목에 대해서 계산한다.\n",
    "\n",
    "> - Pearson 유사도는 대상 사용자와 다른 모든 사용자 간에 계산된다.\n",
    "- 대상 사용자의 유사 그룹을 정의하는 한 가지 방법은 **가장 높은 Pearson 계수를 가진 $k$명의 사용자 집합을 대상과 함께 사용하는 것**이다.\n",
    "- 그러나 대상 사용자의 상위 $k$명의 유사 그룹에서 관찰된 평점의 수는 항목에 따라 크게 다를 수 있기 때문에 각 예측 항목에 대해 개별적으로 대상 사용자에 대해 가장 가까운 $k$명의 사용자의 등급을 사용한다.\n",
    "- 이러한 등급의 가중 평균은 해당 항목의 예측값으로 볼 수 있다.\n",
    "- 여기서 가중치는 사용자의 Pearson 상관 계수이다.\n",
    "- $$ \\hat{r}_{uj} = \\frac{\\sum _{v \\in I_u \\cap I_v} Sim(u, v) \\cdot r_{vj} }{\\sum _{v \\in I_u \\cap I_v} |Sim(u, v)|} $$ \n",
    "\n",
    "> - 이 접근방식의 **주요 문제**는 **다른 사용자들이 서로 다른 스케일로 등급을 지정한다는 것**이다.\n",
    "- 한 사용자는 모든 항목을 높게 평가할 수 있는 반면 다른 사용자는 모든 항목을 부정적으로 평가할 수 있다.\n",
    "- 각 행별로 스케일 조절이 필요한데 $u$ 사용자의 $j$에 대한 항목 등급 $r_{uj}$에서 $u$ 사용자의 등급 평균 $\\mu_u$를 뺀 값으로 한다.\n",
    "- $$ s_{uj} = r_{uj} - \\mu_u \\quad \\forall u \\in \\{1...m\\} \\qquad (2.3) $$\n",
    "\n",
    "> - 이웃 기반 prediction function은 다음과 같다.\n",
    "- $$ \\hat{r}_{uj} = \\mu_u + \\frac{\\sum _{v \\in P_u(j)} Sim(u, v) \\cdot s_{vj} }{\\sum _{v \\in P_u(j)} |Sim(u, v)|} = \\mu_u + \\frac{\\sum _{v \\in P_u(j)} Sim(u, v) \\cdot (r_{vj} - \\mu_v)}{\\sum _{v \\in P_u(j)} |Sim(u, v)|} \\qquad (2.4)$$\n",
    "- $r_{uj}$ 위에 있는 모자 표기법 ^은 원래 등급 매트릭스에서 이미 관측된 것과 반대로 예측 등급을 나타낸다.\n",
    "- $P_u(j)$는 대상 사용자 $u$에 가장 가까운 $k$명의 사용자 집합으로, 항목 $j$에 대한 등급을 지정한 그룹이다.\n",
    "- 대상 사용자 $u$ 와 매우 낮거나 부정적인 상관관계를 가진 사용자는 때때로 $P_u(j)$에서 필터링해야 된다.\n",
    "\n",
    "## 2.3.1.1 Similarity Function Variants\n",
    "\n",
    "> - 유사함수의 몇 가지 다른 변형들이 실제로 사용된다.\n",
    "- 한 가지 변형은 평균으로 스케일 한 값이 아닌 원 등급에 코사인 함수를 사용하는 것이다.\n",
    "- $$ \\mathrm{RawCosine} = \\frac{\\sum _{k \\in I_u \\cap I_v} r_{uk} \\cdot r_{vk} }{\\sqrt{\\sum _{k \\in I_u \\cap I_v} r_{uk}^2} \\cdot \\sqrt{\\sum _{k \\in I_u \\cap I_v} r_{vk}^2}} \\qquad (2.5) $$\n",
    "\n",
    "> - 분모의 정규화를 위해 상호 등급이 아닌 지정된 모든 항목에 기초해 적용 가능하다.\n",
    "- $$ \\mathrm{RawCosine} = \\frac{\\sum _{k \\in I_u \\cap I_v} r_{uk} \\cdot r_{vk} }{\\sqrt{\\sum _{k \\in I_u} r_{uk}^2} \\cdot \\sqrt{\\sum _{k \\in I_v} r_{vk}^2}} \\qquad (2.6) $$\n",
    "- 일반적으로 스케일 적용한 Pearson 상관 계수는 코사인 유사도로 비교하는 것보다 선호된다.\n",
    "\n",
    "> - 유사함수 $Sim(u, v)$의 신뢰성은 $u$와 $v$ 사용자 사이의 공통 등급 수 $|I_u \\cap I_v|$에 의해 영향을 받는 경우가 많다.\n",
    "- 두 명의 사용자가 공통적으로 평가되는 개수가 적을 경우에는 유사성 함수를 할인 계수로 줄여서 그 사용자 쌍의 중요성을 강조하지 않도록 해야 한다.\n",
    "- 이 방법을 **significance weighting**라고 한다.\n",
    "- 할인 계수는 두 사용자 사이의 공통 등급 수가 특정 임계값 $\\beta$ 미만일 때 시작된다.\n",
    "- 할인 계수는 다음과 같고 항상 $[0, 1]$ 범위에 있다.\n",
    "- $$ \\mathrm{DiscountedSim(u, v)} = \\mathrm{Sim(u, v)} \\cdot \\frac{min{(|I_u \\cap I_v|, \\beta)}}{\\beta} \\qquad (2.7) $$\n",
    "- 해당 유사도는 유사 그룹을 결정하는 프로세스와 방정식 $(2.4)$에 따라 예측을 계산하는 데 모두 사용된다.\n",
    "\n",
    "## 2.3.1.2 Variants of the Prediction Function\n",
    "\n",
    "> - 방정식 2.4에 사용된 예측함수의 변형에는 여러 가지가 있다.\n",
    "- 예를 들어 원시 등급인 $r_{uj}$를 $s_{uj}$로 평균을 기준으로 스케일 하는 대신 **$Z$-score로 스케일** 할 수 있다.\n",
    "- 표준 편차는 다음과 같이 정의된다.\n",
    "- $$ \\sigma_u = \\sqrt{\\frac{\\sum _{j \\in I_u}(r_{uj} - \\mu_u)^2}{|I_u| - 1}} \\quad \\forall u \\in \\{1...m\\} \\qquad (2.8)$$\n",
    "- 표준화된 등급은 다음과 같이 계산된다.\n",
    "- $$ z_{uj} = \\frac{r_{uj} - \\mu_u}{\\sigma_u} = \\frac{s_{uj}}{\\sigma_u} \\qquad (2.9) $$\n",
    "- $P_u(j)$는 항목 $j$의 등급이 관찰된 대상 중 사용자 $u$와 높은 유사도를 가진 $k$명의 사용자 집합을 나타낸다.\n",
    "- 이 경우 항목 $j$에 대한 대상 사용자 $u$의 예측 등급 $\\hat r_{uj}$는 다음과 같다.\n",
    "- $$ \\hat{r}_{uj} = \\mu_u + \\sigma_u\\frac{\\sum _{v \\in P_u(j)} Sim(u, v) \\cdot z_{vj} }{\\sum _{v \\in P_u(j)} |Sim(u, v)|} \\qquad (2.10)$$\n",
    "\n",
    "> - 이 경우 $\\sigma_u$를 곱해야 한다는 점에 유의해야 한다.\n",
    "- 일반적으로 등급 정규화 중에 함수 $g(\\cdot)$를 적용하면 최종 예측 과정에서 역 함수 $g(\\cdot)$를 적용할 필요가 있다.\n",
    "- 정규화가 예측을 향상 시킨다는 것이 일반적으로 받아 들여지고 있지만 평균으로 스케일 또는 $Z$-score 가 더 높은 품질의 결과를 제공하는지에 대한 다양한 연구에서 상충되는 결론이 있다.\n",
    "- **$Z$-score의 한 가지 문제는 예측된 등급이 종종 허용 등급 범위를 벗어날 수 있다는 것**이다.\n",
    "- **예측값이 허용 등급 범위를 벗어나더라도 특정 사용자의 만족도 순서에 따라 항목의 순위를 매기는 데 사용할 수 있다.**\n",
    "\n",
    "> - $Sim(u, v)$의 값이 Pearson 상관 계수로 선택되었지만 일반적으로 사용되는 방법은 지수를 $\\alpha$의 거듭 제곱으로 증폭하는 것이다.\n",
    "- $$ Sim(u, v) = Pearson(u, v)^\\alpha \\qquad (2.11) $$\n",
    "- $\\alpha > 1$ 로 등식 2.4의 가중치에서 유사성의 중요성을 증폭시킬 수 있다.\n",
    "\n",
    "> - 앞서 논의한 바와 같이, 이웃 기반 협력 필터링 방법은 가장 가까운 이웃 분류 / 회귀 방법의 일반화이다.\n",
    "- 앞서 언급 한 논의는 예측 된 값이 예측 프로세스 전체에 걸쳐 연속 변수로 처리되기 때문에 가장 가까운 이웃 분류보다는 가장 가까운 이웃 회귀 모델링에 더 가깝다.\n",
    "- 등급을 범주형 값으로 처리하고 등급 간 순서를 무시해 분류 방식에 가까운 예측함수를 만들 수도 있다.\n",
    "    - 일단 타겟 사용자 $u$의 유사 그룹이 식별되면, 그룹 내의 가능한 각 등급 값(동의, 중립, 반대)에 대한 득표 수로 인해 결정된다.\n",
    "    - 가장 많은 표를 얻은 평점이 관련 평점으로 예측이 된다.\n",
    "    - 이 접근 방식은 평균 등급보다는 가능성이 가장 높은 등급을 제공한다는 장점이 있다.\n",
    "    - 이러한 접근 방식은 일반적으로 개별 등급의 수가 적은 경우에 더 효과적이다.\n",
    "    - 또한 등급 값 사이의 정확한 거리가 정의되지 않은 등급에서도 유용하다.\n",
    "    - 등급의 세분성이 높은 경우 이러한 접근 방식은 덜 강력하며 등급간에 많은 순서 정보가 손실된다.\n",
    "    \n",
    "## 2.3.1.3 Variations in Filtering Peer Groups\n",
    "\n",
    "> - 대상 사용자에 대한 유사 그룹은 다양한 방식으로 정의되고 필터링 될 수 있다.\n",
    "- **가장 간단한 접근법은 대상 사용자와 가장 유사한 상위 $k$명의 사용자를 자신의 유사 그룹으로 사용하는 것이다.**\n",
    "- 그러나 이러한 접근 방식에는 **대상과 약하거나 부정적인 상관 관계가 있는 사용자가 포함될 수 있다.**\n",
    "- 약한 상관 관계가 있는 사용자는 예측에 오류를 추가 할 수 있다.\n",
    "- 예측 기능은 기술적으로 약하거나 부정적인 등급의 사용을 허용하지만 그 사용은 이웃 방법의 광범위한 원칙과 일치하지 않다.\n",
    "- **따라서 상관관계가 약하거나 부정적인 등급을 걸러내는 경우가 많다.**\n",
    "\n",
    "## 2.3.1.4 Impact of the Long Tail\n",
    "\n",
    "> - 2.2에서 언급했듯이 **등급 분포는 일반적으로 많은 실제 시나리오에서 `롱테일` 분포로 나타난다.**\n",
    "- 일부 영화는 매우 인기가 있어 여러 사용자로부터 공통으로 평가한 항목이 된다.\n",
    "- 이러한 항목은 여러 사용자에 대해 덜 차별적인 경향이 있기 때문에 때때로 추천의 품질을 저하시킬 수 있다.\n",
    "- 이 개념은 원칙적으로 문서 검색에서 인기있는 비 정보 단어 (예 : \"a\", \"an\", \"the\")로 인한 검색 품질 저하와 유사하다.\n",
    "- 따라서 협업 필터링에 사용되는 솔루션은 정보 검색에 사용되는 솔루션과도 유사하다.\n",
    "- 정보 검색 문헌에 idf의 개념이 존재하는 것처럼, $Inverse$ $User$ $Frequency$라는 개념을 사용할 수 있다.\n",
    "- $m_j$가 항목 $j$의 등급 수이고 $m$이 총 사용자 수인 경우 항목 $j$의 가중치 $w_j$는 다음과 같이 설정된다.\n",
    "- $$ w_j = log(\\frac{m}{m_j}) \\quad \\forall j \\in \\{1...n\\} \\qquad (2.12) $$\n",
    "- 각 항목 $j$는 유사성 계산 및 추천 프로세스 중에 $w_j$에 의해 가중치가 부여된다.\n",
    "- 예를 들어 Pearson 상관 계수는 다음과 같은 가중치를 포함하도록 수정할 수 있다.\n",
    "- $$ Pearson(u, v) = \\frac{\\sum _{k \\in I_u \\cap I_v} w_k \\cdot (r_{uk} - \\mu_u) \\cdot (r_{vk} - \\mu_v)}{ \\sqrt{\\sum _{k \\in I_u \\cap I_v} w_k \\cdot (r_{uk} - \\mu_u)^2 } \\cdot \\sqrt{\\sum _{k \\in I_u \\cap I_v} w_k \\cdot (r_{vk} - \\mu_v)^2 }} \\qquad (2.13) $$\n",
    "- 항목 가중치는 다른 협업 필터링 방법에도 통합 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.2 Item-Based Neighborhood Models\n",
    "\n",
    "> - **항목 기반 모델에서 유사 그룹은 사용자보다는 항목 단위로 구성된다.**\n",
    "    - 따라서 항목 간의 유사도를 계산해야 한다.\n",
    "- 항목 간의 유사도를 계산하기 전에, 등급 매트릭스의 각 행의 평균을 0으로 만든다.\n",
    "- 사용자 기반 등급의 경우와 마찬가지로 등급 매트릭스에 있는 각 항목의 평균 등급을 각 등급에서 빼서 평균이 0인 매트릭스를 만든다.\n",
    "- 이 프로세스는 앞에서 설명한 것과 동일하며(수식 2.3 참조) $s_{uj}$를 계산한다.\n",
    "- $U_i$를 항목 $i$에 대한 등급을 지정한 사용자 집합의 인덱스로 지정하자.\n",
    "    - 예를 들어 첫 번째, 세 번째, 네 번째 사용자가 항목 $i$에 대한 등급을 지정했다면 $U_i = \\{1, 3, 4\\}$이(가) 있는 것이다.\n",
    "\n",
    "> - 항목 $i$와 $j$ 사이의 수정된 코사인 유사도는 다음과 같이 정의된다.\n",
    "- $$ AdjustedCosine(i, j) = \\frac{\\sum _{u \\in U_i \\cap U_j} s_{ui} \\cdot s_{uj}}{\\sqrt{\\sum _{u \\in U_i \\cap U_j} s_{ui}^2} \\cdot \\sqrt{\\sum _{u \\in U_i \\cap U_j} s_{uj}^2}} \\qquad (2.14)$$\n",
    "- 이 유사도는 유사도 값을 계산하기 전에 등급의 평균이 0이기 때문에 수정된 코사인 유사도라고 한다.\n",
    "- **아이템 기반 방법의 경우 Pearson 상관관계를 사용할 수 있지만, 일반적으로 수정된 코사인이 우수한 결과를 제공한다.**\n",
    "\n",
    "> - 사용자 $u$에 대한 대상 항목 $t$의 등급을 결정해야 하는 경우를 고려해보자.\n",
    "- 첫 번째로 앞서 언급한 수정된 코사인 유사도에 기초하여 항목 $t$와 가장 유사한 상위 $k$개의 항목을 결정하는 것이다.\n",
    "- 사용자 $u$가 등급을 지정한 항목 $t$에 대한 상위 $k$ 일치 항목을 $Q_t(u)$라고 한다.\n",
    "- 이러한 등급의 가중 평균 값이 예측값이 된다.\n",
    "- 이때 가중치는 항목 $j$와 대상 항목 $t$ 사이의 조정된 코사인 유사도이다.\n",
    "- 따라서 대상 항목 $t$에 대한 사용자 $u$의 예측 등급 $\\hat r_{ut}$는 다음과 같다.\n",
    "- $$ \\hat r_{ut} = \\frac{\\sum _{j \\in Q_t(u)} AdjustedCosine(j,t) \\cdot r_{uj}}{\\sum _{j \\in Q_t(u)} |AdjustedCosine(j,t)|} $$\n",
    "\n",
    "> - **기본 아이디어는 예측의 마지막 단계에서 유사한 항목에 대한 사용자 자신의 평가를 활용하는 것이다.**\n",
    "- 예를 들어, 영화 추천 시스템에서 항목 유사 그룹은 일반적으로 비슷한 장르의 영화가 될 것이다.\n",
    "- 이러한 영화에서 동일한 사용자의 평가 기록은 해당 사용자의 관심사에 대한 매우 신뢰할 수있는 예측 변수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.3 Efficient Implementation and Computational Complexity\n",
    "\n",
    "> - **`이웃 기반 방법`은 항상 대상 사용자에 대한 최상의 항목 추천 또는 대상 항목에 대한 최상의 사용자를 결정하는 데 사용된다.**\n",
    "- 앞서 언급한 논의는 특정 사용자-항목 조합에 대한 등급을 예측하는 방법만 보여줄 뿐 실제 순위를 결정하는 과정은 논의하지 않는다.\n",
    "- 이에 대해 간단한 접근방식은 관련 사용자-항목 쌍에 대해 가능한 모든 등급 예측을 계산한 다음 순위를 매기는 것이다.\n",
    "- 이는 현재 추천 시스템에서 사용되는 기본 접근법이지만 많은 사용자-항목 조합에 대한 예측 프로세스가 많은 중간 단계를 재사용한다는 것이다.\n",
    "- 따라서 이러한 중간 연산을 저장 후 순위 결정 과정에서 활용하는 오프라인 단계를 갖는 것이 바람직하다.\n",
    "\n",
    "> - **이웃 기반 방법은 항상 오프라인 단계와 온라인 단계로 분할된다.**\n",
    "- 오프라인 단계에서는 사용자(또는 항목)간의 유사도와 사용자(또는 항목)의 유사 그룹을 계산한다.\n",
    "- 각 사용자(또는 항목)에 대해 관련 유사 그룹은 이 계산에 기초하여 미리 저장된다.\n",
    "- 온라인 단계에서는 유사도 값과 유사 그룹을 활용해 방정식 $(2.4)$와 같은 관계를 사용하여 예측한다.\n",
    "- $n$은 사용자(행)가 지정한 등급의 최대 개수이고 $m$은 항목(열)에 지정된 등급의 최대 개수로 하자.\n",
    "- $n'$은 한 쌍의 사용자(행)간의 유사도를 계산하기 위한 최대 실행 시간이며, $m'$은 한 쌍의 항목(열)간의 유사도를 계산하기 위한 최대 실행 시간이다.\n",
    "- **사용자 기반 방법의 경우, 대상 사용자의 유사 그룹을 결정하는 과정에는 $O(m·n')$ 시간**이 필요하다.\n",
    "- 따라서 **모든 사용자의 유사 그룹을 계산하기 위한 오프라인 실행 시간복잡도는 $O(m^2 \\cdot n')$**에 의해 주어진다.\n",
    "- 항목 기반 방법의 경우 오프라인 실행 시간복잡도는 $O(n^2 \\cdot m')$이다.\n",
    "\n",
    "> - $k$의 값에 따라 나타나는 여러 결괏값을 사용하기 위해서는 결국 사용자 쌍(또는 항목)사이에 0이 아닌 유사도를 모두 저장해야 할 수도 있다.\n",
    "- 따라서 사용자 기반 방법의 공간복잡도는 $O(m^2)$인 반면, 항목 기반 방법의 공간복잡도는 $O(n^2)$이다.\n",
    "- 사용자 수가 일반적으로 항목 수보다 크기 때문에 사용자 기반 방법의 공간 요구사항은 일반적으로 항목 기반 방법의 공간 요구사항보다 크다.\n",
    "\n",
    "> - 방정식 $(2.4)$에 따른 예측값의 **온라인 계산은 사용자 기반 및 항목 기반 방법 모두에 대해 $O(k)$ 시간이 필요**하며, 여기서 $k$는 예측에 사용되는 사용자/항목 유사 그룹의 크기이다.\n",
    "- 또한, **대상 사용자에 대한 항목 순위**를 정하기 위해 모든 항목에 대해 이 예측을 실행해야 하는 경우, 사용자 기반 및 항목 기반 방법 모두에 대해 실행 시간은 **$O(k \\cdot n)$**이다.\n",
    "- 반면에, 상인은 때때로 특정 품목의 표적이 될 상위 $r$명의 사용자를 알고 싶을 수 있다.\n",
    "- 이 경우 **대상 항목에 대한 사용자 순위**를 정하기 위해서는 모든 사용자에 걸쳐 예측을 실행해야 하며, 사용자 기반 및 항목 기반 방법 모두에 대해 실행 시간은 **$O(k \\cdot m)$**이다.\n",
    "- **이웃 기반 방법의 주요 시간복잡도는 가끔 실행해야하는 오프라인 단계에 있다.**\n",
    "- 결과적으로 이웃 기반 방법은 온라인 예측에 사용될 때 효율적인 경향이 있다.\n",
    "- 결국 오프라인 단계에 훨씬 더 많은 계산 시간을 할당 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.4 Comparing User-Based and Item-Based Methods\n",
    "\n",
    "> - **항목 기반 방법은 사용자 자신의 평가를 사용하여 추천을 수행하기 때문에 더 관련성 높은 추천을 제공하는 경우가 많다.**\n",
    "- 항목 기반 방법에서는 대상 항목과 유사한 항목을 식별하고, 그 항목에 대한 사용자 자신의 등급을 이용하여 대상의 등급을 추론한다.\n",
    "- 결과적으로, 항목 기반 방법은 종종 사용자 기반 방법 보다 더 나은 정확성을 볼 수 있다.\n",
    "\n",
    "> - 항목 기반 권장 사항이 정확할 가능성이 더 높지만 항목 기반 방법과 사용자 기반 방법 간의 상대적 정확도는 data set에 따라 달라진다.\n",
    "- 12장에서 언급되겠지만, 추천시스템에서 **항목 기반 방법은 실링 공격에 더 강력**하다.\n",
    "- 반면에, **항목 기반 방법보다 사용자 기반 방법을 사용할 때 더 많은 다양한 추천을 볼 수 있다.**\n",
    "    - **`다양성(diversity)`**이란 순위에 오른 항목들이 다소 다른 경향을 보이는 것을 말한다.\n",
    "- 항목이 다양하지 않을때 사용자가 첫 번째 항목을 좋아하지 않으면 목록에 있는 다른 항목도 좋아하지 않을 수 있다.\n",
    "- 다양성이 커지면 우연성이 높아지며, 그 결과 다소 놀랍고 흥미로운 항목이 발견된다.\n",
    "- 항목 기반 방법은 때때로 명백한 항목 또는 이전 사용자 경험에서 새로운 항목이 아닌 항목을 추천할 수 있다.\n",
    "- 참신성, 다양성, 우연성에 대한 개념은 7장에 있다.\n",
    "- 참신함, 다양성 및 우연이 없으면 사용자는 이미 시청한 것과 매우 유사한 추천에 지루할 수 있다.\n",
    "- <img src=\"../image/2_3.png\" width = 500 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 항목 기반 방법은 추천 항목에 대한 구체적인 이유를 제공 할 수도 있다.\n",
    "- 예를 들어 넷플릭스는 다음과 같은 문장으로 추천을 제공하는 경우가 많다.\n",
    "    - 당신은 $A$를 시청했기 때문에 $\\{B, C, ...\\}$ 를 추천한다.\n",
    "- 이러한 설명은 유사 항목을 이용해 항목 기반 방법으로 구체적으로 설명할 수 있다.\n",
    "- 반면에, 이러한 설명은 사용자 기반 방법으로 다루기 어렵다. \n",
    "    - 왜냐하면 유사 그룹은 단순히 익명 사용자들의 집합이고 추천 프로세스에서 직접 사용할 수 없기 때문이다.\n",
    "    \n",
    "> - 사용자 기반 방법은 다른 종류의 설명을 제공한다.\n",
    "    - 예를 들어, 영화 터미네이터, 에일리언, 프레데터등이 $A$에게 추천되는 시나리오를 생각해 보자.\n",
    "    - 그런 다음, 이 영화들에 대한 유사 그룹의 rating 히스토그램을 $A$에게 보여줄 수 있다.\n",
    "    - 그러한 히스토그램의 예는 그림 $(2.2)$에 나와 있다.\n",
    "    - 이 히스토그램은 $A$가 이 영화를 얼마나 좋아할지에 대한 아이디어를 얻기 위해 사용할 수 있다.\n",
    "    - 그럼에도 불구하고, 이러한 유형의 설명은 $A$에게 이 영화들이 자신의 취향이나 다른 사용자와 어떻게 관련되는지에 대한 생각을 주지 않기 때문에 다소 제한적이다.\n",
    "    - $A$는 프라이버시 문제로 인해 유사 사용자들의 신원을 알 수 없다.\n",
    "    \n",
    "> - 마지막으로 **항목 기반 방법은 등급이 변경됨에 따라 더 안정적이다.**\n",
    "- 이것은 다음과 같은 두 가지 이유 때문이다.\n",
    "- **첫째로, 사용자 수는 일반적으로 항목 수보다 훨씬 많다.**\n",
    "    - 두 명의 사용자가 상호 등급이 매겨진 항목의 수는 대체적으로 적지만 두 항목을 공동으로 평가된 사용자는 많은 편이다.\n",
    "    - 사용자 기반 방법의 경우, 몇 개의 등급이 추가되면 유사도 값이 급격하게 변할 수 있다.\n",
    "- **두번째로, 시스템에서 신규 사용자들이 신규 항목보다 더 자주 추가될 가능성이 높다.**\n",
    "    - 새로운 사용자가 추가됨에 따라 유사 항목이 급격히 변하지 않을 가능성이 높기 때문에 유사 항목의 계산은 때때로만 수행할 수 있다.\n",
    "    - 반면에, 사용자 유사도 계산은 새로운 사용자가 추가됨에 따라 수행이 되야 한다.\n",
    "    - 이러한 점에서 사용자 기반 방법의 경우 추천 모델의 점진적인 유지보수가 더 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.5 Strengths and Weaknesses of Neighborhood-Based Methods\n",
    "\n",
    "> - **이웃기반 추천은 `단순성`과 `직관적인 접근 방식`과 관련된 몇 가지 장점이 있다.**\n",
    "- 이러한 장점 때문에 구현과 디버깅이 용이하다.\n",
    "- 특정 항목을 추천하는 이유를 정당화하기가 쉬운 경우가 많고, 항목 기반 방법의 해석성이 특히 두드러진다.\n",
    "- 이러한 정당화는 종종 후속장에서 논의될 많은 모델 기반 방법에서 쉽게 이용할 수 없다.\n",
    "- 또한 새로운 항목과 사용자가 추가됨에 따라 추천이 비교적 안정적이게 된다.\n",
    "- 또한 이러한 방법의 증분적 근사치를 생성할 수도 있다.\n",
    "\n",
    "> - **주요 단점은 오프라인 단계의 `대규모 계산`에서 비실용적일 수 있다는 것이다.**\n",
    "    - 사용자 기반 방법의 오프라인 단계에는 최소한 $O(m^2)$의 시간과 공간이 필요하다.\n",
    "    - $m$이 수천만 명일때 데스크톱 하드웨어의 속도가 너무 느리거나 공간 집약적일 수 있다.\n",
    "    - 그럼에도 불구하고 **이웃기반 방법의 온라인 단계는 항상 효율적**이다.\n",
    "- 이 방법의 또 **다른 주요 단점은 `희소성` 때문에 제한된 적용 범위**입니다.\n",
    "    - 예를 들어, 존의 가장 가까운 이웃들 중 어느 누구도 터미네이터 등급을 매기지 않은 경우에는 존에 대한 터미네이터 등급 예측을 제공할 수 없다.\n",
    "    - 희소성은 또한 두 사용자 간의 상호 평가 항목 수가 적을 때 유사도에 대한 의심을 갖게 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.6 A Unified View of User-Based and Item-Based Methods\n",
    "\n",
    "> - 사용자 기반 방법과 항목 기반 방법의 각각의 약점은 전자가 등급 매트릭스 열의 유사성을 무시하는 반면 후자는 가장 유사한 항목을 결정하면서 행 간의 유사성을 무시한다.\n",
    "- 두 가지 방법을 통일해 목표 항목과 가장 유사한 항목을 결정할 수 있는지에 대한 의문이 생긴다.\n",
    "- 이렇게하면 행이나 열의 유사성을 무시할 필요가 없게 되고 행과 열의 유사성 정보를 결합할 수 있게 된다.\n",
    "- 이 목표를 달성하기 위해서는 일단 행을 정규화를 하면 사용자 기반 방법과 항목 기반 방법 일부 사소한 차이가 있지만 거의 동일하다는 것을 알 수 있다.\n",
    "- 또한 행이 정규화가 되면 행 간의 Pearson 상관 계수가 코사인 계수와 동일하게 된다.\n",
    "- 다음 가정을 기반으로 사용자 기반 및 항목 기반 방법을 통합 방식으로 등급 행렬 $R$의 항목 $r_{uj}$을 예측할 수 있다.\n",
    "\n",
    "> - 1) 대상 항목 $(u, j)$의 경우 행과 열 간의 유사성 조합 함수를 사용하여 등급 행렬의 가장 유사한 항목을 결정한다. 예를 들어, 행과 열 사이의 코사인 유사성의 합을 사용하여 $(u, j)$의 등급 매트릭스에서 가장 유사한 항목을 결정할 수 있다.\n",
    "- 2) 첫 번째 단계에서 결정된 가장 유사한 항목에서 등급의 가중 조합을 사용하여 대상 항목$(u, j)$을 예측한다. 가중치는 첫 번째 단계에서 계산된 유사도에 기반한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
